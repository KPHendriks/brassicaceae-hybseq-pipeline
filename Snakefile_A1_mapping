SAMPLES = "SRR8528376 SRR8528377".split()
FRPU = ["forward_trim_paired", "forward_trim_unpaired", "reverse_trim_paired", "reverse_trim_unpaired"]

raw_reads_samples = expand("data/raw_reads/{sample}_count_reads.txt", sample = SAMPLES)
count_trimmed_reads = expand("results/A01_trimmed_reads/{sample}/{sample}_count_reads.txt", sample = SAMPLES)
dedupl_var = expand("results/A02_deduplicated_reads/{sample}/{sample}_{frpu}_dedupl.fq", sample = SAMPLES, frpu = FRPU)
count_dedupl_reads = expand("results/A02_deduplicated_reads/{sample}/{sample}_count_reads.txt", sample = SAMPLES)
combine = expand("results/A02_deduplicated_reads/{sample}/{sample}_reads.fq", sample = SAMPLES)
alignreads = expand("{sample}/", sample = SAMPLES)
extract_contigs = expand("results/A04_mapped_contigs/{sample}/sam", sample = SAMPLES)

rule all:
    input:
        raw_reads_samples,
        count_trimmed_reads,
        dedupl_var,
        combine,
        count_dedupl_reads,
        alignreads,
        extract_contigs

rule count_raw_reads:
    input:
        forward="data/raw_reads/{sample}_1.fastq",
        reverse="data/raw_reads/{sample}_2.fastq"
    output:
        "data/raw_reads/{sample}_count_reads.txt"
    shell:
        "echo $(cat {input.forward} | grep '@SRR' | wc -l) + $(cat {input.reverse} | grep '@SRR' | wc -l) | "
        "bc > {output}"

rule trimming:
    input:
        "data/raw_reads/{sample}_1.fastq",
        "data/raw_reads/{sample}_2.fastq"
    output:
        expand("results/A01_trimmed_reads/{{sample}}/{{sample}}_{FRPU}.fq", FRPU = FRPU)
    shell:
        "trimmomatic PE -phred33 {input} {output} "
        "ILLUMINACLIP:trimmomatic_adapter/TruSeq3-PE-2.fa:2:30:10 "
        "LEADING:20 "
        "TRAILING:20 "
        "SLIDINGWINDOW:5:20 "
        "MINLEN:36"

rule count_trimmed_reads:
    input:
        expand("results/A01_trimmed_reads/{{sample}}/{{sample}}_{FRPU}.fq", FRPU = FRPU)
    output:
        "results/A01_trimmed_reads/{sample}/{sample}_count_reads.txt"
    shell:
        "echo $(cat {input} | wc -l)/4|bc >> {output}"

rule deduplication:
    input:
        "results/A01_trimmed_reads/{{sample}}/{{sample}}_{frpu}.fq"
    output:
        "results/A02_deduplicated_reads/{{sample}}/{{sample}}_{frpu}_dedupl.fq"
    shell:
        "fastx_collapser -v -i {input} -o {output}"

rule combine:
    input:
        expand("results/A02_deduplicated_reads/{{sample}}/{{sample}}_{FRPU}_dedupl.fq", FRPU = FRPU)
    output:
        "results/A02_deduplicated_reads/{sample}/{sample}_reads.fq"
    shell:
        "cat {input} > {output}"

rule count_deduplicated_reads:
    input:
        "results/A02_deduplicated_reads/{sample}/{sample}_reads.fq"
    output:
        "results/A02_deduplicated_reads/{sample}/{sample}_count_reads.txt"
    shell:
        "grep '>' {input} | wc -l > {output}"

# reference mapping and de novo using YASRA/alignreads.py
# make sure to: $ export PATH="$PATH:~/usr/local/src/alignreads/alignreads"
rule alignreads:
    input:
        "results/A02_deduplicated_reads/{sample}/{sample}_reads.fq",
        "data/reference_genomes/ref-at.fasta"
    output:
        "{sample}/"
    shell:
        "python src/installed_alignreads/alignreads/alignreads.py "
        "{input} "
        "--single-step "
        "--read-type solexa "
        "--read-orientation linear "
        "--percent-identity medium "
        "--depth-position-masking 5- "
        "--proportion-base-filter 0.7- "
        "--output-directory {output}"

# extract contigs from created SAM file after YASRA and create per contig new SAM files with headers
rule extract_contigs:
    input:
        "src/extract_contigs_YASRA.py"
    output:
        "results/A04_mapped_contigs/{sample}/sam"
    params:
        "{sample}"
    shell:
        "python3 {input} {params}"
