SAMPLES = "S0275 S0277".split() #PJA296A PJA370-B PJA370-C
ORIGIN = "naturalis"

# variables for part 1 and 2:
if ORIGIN == "naturalis":
    origin = "@A00"
elif ORIGIN == "nikolov":
    origin = "@SRR"
elif ORIGIN == "donovan":
    origin = "@M01"
else:
    print("ORIGIN input should be 'naturalis', 'nikolov' or 'donovan'")

FRPU = ["forward_trim_paired", "forward_trim_unpaired", "reverse_trim_paired", "reverse_trim_unpaired"]

raw_reads_samples = expand("data/raw_reads/{sample}_count_reads.txt", sample = SAMPLES)
count_trimmed_reads = expand("results/A01_trimmed_reads/{sample}/{sample}_count_reads.txt", sample = SAMPLES)
dedupl_var = expand("results/A02_deduplicated_reads/{sample}/{sample}_{frpu}_dedupl.fq", sample = SAMPLES, frpu = FRPU)
count_dedupl_reads = expand("results/A02_deduplicated_reads/{sample}/{sample}_count_reads.txt", sample = SAMPLES)
combine = expand("results/A02_deduplicated_reads/{sample}/{sample}_reads.fq", sample = SAMPLES)
alignreads = expand("results/A04_mapped_contigs/{sample}/", sample = SAMPLES)
extract_contigs = expand("results/A04_mapped_contigs/{sample}/sam/number_of_reads_and_contigs.txt", sample = SAMPLES)

## rule all:
rule part1:
    input:
        raw_reads_samples,
        count_trimmed_reads,
        dedupl_var,
        combine,
        count_dedupl_reads,
        alignreads

rule part2:
    input:
        extract_contigs

## part1:
rule count_raw_reads:
    input:
        forward="data/raw_reads/{sample}_1.fastq",
        reverse="data/raw_reads/{sample}_2.fastq"
    output:
        "data/raw_reads/{sample}_count_reads.txt"
    params:
        origin=origin
    shell:
        "echo $(cat {input.forward} | grep {params.origin} | wc -l) + $(cat {input.reverse} | "
        "grep {params.origin}  | wc -l) | bc > {output}"

rule trimming:
    input:
        "data/raw_reads/{sample}_1.fastq",
        "data/raw_reads/{sample}_2.fastq"
    output:
        expand("results/A01_trimmed_reads/{{sample}}/{{sample}}_{FRPU}.fq", FRPU = FRPU)
    shell:
        "trimmomatic PE -phred33 {input} {output} "
        "ILLUMINACLIP:trimmomatic_adapter/TruSeq3-PE-2.fa:2:30:10 "
        "LEADING:20 "
        "TRAILING:20 "
        "SLIDINGWINDOW:5:20 "
        "MINLEN:36"

rule count_trimmed_reads:
    input:
        expand("results/A01_trimmed_reads/{{sample}}/{{sample}}_{FRPU}.fq", FRPU = FRPU)
    output:
        "results/A01_trimmed_reads/{sample}/{sample}_count_reads.txt"
    shell:
        "echo $(cat {input} | wc -l)/4|bc >> {output}"

rule deduplication:
    input:
        "results/A01_trimmed_reads/{sample}/{sample}_{frpu}.fq"
    output:
        "results/A02_deduplicated_reads/{sample}/{sample}_{frpu}_dedupl.fq"
    shell:
        "fastx_collapser -v -i {input} -o {output}"

rule combine:
    input:
        expand("results/A02_deduplicated_reads/{{sample}}/{{sample}}_{FRPU}_dedupl.fq", FRPU=FRPU)
    output:
        "results/A02_deduplicated_reads/{sample}/{sample}_reads.fq"
    shell:
        "cat {input} > {output}"

rule count_deduplicated_reads:
    input:
        "results/A02_deduplicated_reads/{sample}/{sample}_reads.fq"
    output:
        "results/A02_deduplicated_reads/{sample}/{sample}_count_reads.txt"
    shell:
        "grep '>' {input} | wc -l > {output}"

# reference mapping and de novo using YASRA/alignreads.py
# make sure to: $ export PATH="$PATH:~/usr/local/src/alignreads/alignreads"
# for high-mem: "alignreads" as shell command
# for laptop: "python src/installed_alignreads/alignreads/alignreads.py "
rule alignreads:
    input:
        reads = "results/A02_deduplicated_reads/{sample}/{sample}_reads.fq",
        reference = "data/reference_genomes/ref-at.fasta"
    output:
        directory("results/A04_mapped_contigs/{sample}/")
    shell:
        "alignreads "
        "{input.reads} {input.reference} "
        "--single-step "
        "--read-type solexa "
        "--read-orientation linear "
        "--percent-identity medium "
        "--depth-position-masking 5- "
        "--proportion-base-filter 0.7- "


## part2:
#create per contig new SAM files with headers from created SAM file after YASRA
rule extract_contigs:
    input:
        "src/extract_contigs_YASRA.py"
    output:
        "results/A04_mapped_contigs/{sample}/sam/number_of_reads_and_contigs.txt"
    params:
        "{sample}"
    shell:
        "python {input} {params}"

