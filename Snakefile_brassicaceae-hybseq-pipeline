SAMPLES = "S0603 S0560".split() #PJA296A PJA370-B PJA370-C
ORIGIN = "naturalis"

# variables for part 1 and 2:
if ORIGIN == "naturalis":
    origin = "@A00"
elif ORIGIN == "nikolov":
    origin = "@SRR"
elif ORIGIN == "donovan":
    origin = "@M01"
else:
    print("ORIGIN input should be 'naturalis', 'nikolov' or 'donovan'")

FRPU = ["forward_trim_paired", "forward_trim_unpaired", "reverse_trim_paired", "reverse_trim_unpaired"]

raw_reads_samples = expand("data/raw_reads/{sample}_count_reads.txt", sample = SAMPLES)
count_trimmed_reads = expand("results/A01_trimmed_reads/{sample}/{sample}_count_reads.txt", sample = SAMPLES)
dedupl_var = expand("results/A02_deduplicated_reads/{sample}/{sample}_{frpu}_dedupl.fq", sample = SAMPLES, frpu = FRPU)
count_dedupl_reads = expand("results/A02_deduplicated_reads/{sample}/{sample}_count_reads.txt", sample = SAMPLES)
combine = expand("results/A02_deduplicated_reads/{sample}/{sample}_reads.fq", sample = SAMPLES)
alignreads = expand("results/A04_mapped_contigs/{sample}/", sample = SAMPLES)
extract_contigs = expand("results/A04_mapped_contigs/{sample}/sam/number_of_reads_and_contigs.txt", sample = SAMPLES)

# variables for part 3:
configfile: "./envs/config_contigs.yaml"

var_variables = []
make_contig_consensus = []
blat_variables = []
for sample in SAMPLES:
    if sample in config:
        contig_nrs = config[sample]
        if not contig_nrs:
            print("not a single contig has been formed in: " + sample)
        elif contig_nrs:
            for nr in contig_nrs:
                var_variables.append("results/A04_mapped_contigs/{sample}/var/Contig{nr}_AT_sort.var".format(sample=sample, nr=nr))
                make_contig_consensus.append("results/A05_consensus_contigs/{sample}/Contig{nr}.fasta".format(sample=sample, nr=nr))
                blat_variables.append("results/A06_identified_contigs_blat/{sample}/contig{nr}_AT.psl".format(sample=sample, nr=nr))
    else:
        print(sample + " is not yet in config_contigs.yaml file. Part 2 has to be ran first for this sample.")

# variables for part 4:
calculate_avcov = []
extract_hits_psl = []
calc_mapped_reads = []
calc_contigs_formed = []
for sample in SAMPLES:
    calculate_avcov.append("results/A04_mapped_contigs/{sample}/var/{sample}_average_coverage.txt".format(sample=sample))
    extract_hits_psl.append("results/A07_mapped_exons/{sample}/stats/sequenced_exons.txt".format(sample=sample))
    calc_mapped_reads.append("results/A03_mapped_reads/{sample}/mapped_reads.txt".format(sample=sample))
    calc_contigs_formed.append("results/A03_mapped_reads/{sample}/contigs_formed.txt".format(sample=sample))

# variables for part 5:
configfile: "./envs/config_exons.yaml"
mafft_variables = []
make_exon_consensus = []
calc_called_exons = []
calc_id_contigs = []
for sample in SAMPLES:
    calc_id_contigs.append("results/A06_identified_contigs_blat/{sample}/stats/identified_contigs.txt".format(sample=sample))
    if sample in config:
        exons = config[sample]
        if not exons:
            print("not a single exon has been identified in: " + sample)
        elif exons:
            for exon in exons:
                mafft_variables.append("results/A08_aligned_exons/{sample}/{exon}.fasta".format(sample=sample, exon=exon))
                make_exon_consensus.append("results/A09_consensus_exons/{sample}/{exon}.fasta".format(sample=sample, exon=exon))
                calc_called_exons.append("results/A09_consensus_exons/{sample}/called_exons.txt".format(sample=sample))
    else:
        print(sample + " is not yet in config_exons.yaml file. Part 4 has to be ran first for this sample.")


## rule all:
rule part1:
    input:
        raw_reads_samples,
        count_trimmed_reads,
        dedupl_var,
        combine,
        count_dedupl_reads,
        alignreads

rule part2:
    input:
        extract_contigs

rule part3:
    input:
        var_variables,
        make_contig_consensus,
        blat_variables

rule part4:
    input:
       calculate_avcov,
       extract_hits_psl,
       calc_mapped_reads,
       calc_contigs_formed

rule part5:
    input:
        mafft_variables,
        make_exon_consensus,
        calc_id_contigs

rule part6:
    input:
        calc_called_exons


## part1:
rule count_raw_reads:
    input:
        forward="data/raw_reads/{sample}_1.fastq",
        reverse="data/raw_reads/{sample}_2.fastq"
    output:
        "data/raw_reads/{sample}_count_reads.txt"
    params:
        origin=origin
    shell:
        "echo $(cat {input.forward} | grep {params.origin} | wc -l) + $(cat {input.reverse} | "
        "grep {params.origin}  | wc -l) | bc > {output}"

rule trimming:
    input:
        "data/raw_reads/{sample}_1.fastq",
        "data/raw_reads/{sample}_2.fastq"
    output:
        expand("results/A01_trimmed_reads/{{sample}}/{{sample}}_{FRPU}.fq", FRPU = FRPU)
    shell:
        "trimmomatic PE -phred33 {input} {output} "
        "ILLUMINACLIP:trimmomatic_adapter/TruSeq3-PE-2.fa:2:30:10 "
        "LEADING:20 "
        "TRAILING:20 "
        "SLIDINGWINDOW:5:20 "
        "MINLEN:36"

rule count_trimmed_reads:
    input:
        expand("results/A01_trimmed_reads/{{sample}}/{{sample}}_{FRPU}.fq", FRPU = FRPU)
    output:
        "results/A01_trimmed_reads/{sample}/{sample}_count_reads.txt"
    shell:
        "echo $(cat {input} | wc -l)/4|bc >> {output}"

rule deduplication:
    input:
        "results/A01_trimmed_reads/{sample}/{sample}_{frpu}.fq"
    output:
        "results/A02_deduplicated_reads/{sample}/{sample}_{frpu}_dedupl.fq"
    shell:
        "fastx_collapser -v -i {input} -o {output}"

rule combine:
    input:
        expand("results/A02_deduplicated_reads/{{sample}}/{{sample}}_{FRPU}_dedupl.fq", FRPU=FRPU)
    output:
        "results/A02_deduplicated_reads/{sample}/{sample}_reads.fq"
    shell:
        "cat {input} > {output}"

rule count_deduplicated_reads:
    input:
        "results/A02_deduplicated_reads/{sample}/{sample}_reads.fq"
    output:
        "results/A02_deduplicated_reads/{sample}/{sample}_count_reads.txt"
    shell:
        "grep '>' {input} | wc -l > {output}"

# reference mapping and de novo using YASRA/alignreads.py
# make sure to: $ export PATH="$PATH:~/usr/local/src/alignreads/alignreads"
# for high-mem: "alignreads" as shell command
# for laptop: "python src/installed_alignreads/alignreads/alignreads.py "
rule alignreads:
    input:
        reads = "results/A02_deduplicated_reads/{sample}/{sample}_reads.fq",
        reference = "data/reference_genomes/ref-at.fasta"
    output:
        directory("results/A04_mapped_contigs/{sample}/")
    shell:
        "alignreads "
        "{input.reads} {input.reference} "
        "--single-step "
        "--read-type solexa "
        "--read-orientation linear "
        "--percent-identity medium "
        "--depth-position-masking 5- "
        "--proportion-base-filter 0.7- "


## part2:
#create per contig new SAM files with headers from created SAM file after YASRA
rule extract_contigs:
    input:
        "src/extract_contigs_YASRA.py"
    output:
        "results/A04_mapped_contigs/{sample}/sam/number_of_reads_and_contigs.txt"
    params:
        "{sample}"
    shell:
        "python3 {input} {params}"


## part 3:
rule convert_to_fBAM:
    input:
        "results/A04_mapped_contigs/{sample}/sam/Contig{nr}_AT.sam"
    output:
        temp("results/A04_mapped_contigs/{sample}/bam/Contig{nr}_AT.bam")
    shell:
        "samtools view -bS {input} > {output}"

rule sort_fBAM:
    input:
        "results/A04_mapped_contigs/{sample}/bam/Contig{nr}_AT.bam"
    output:
        temp("results/A04_mapped_contigs/{sample}/sorted_bam/Contig{nr}_AT_sort.bam")
    shell:
        "samtools sort -m5G {input} -o {output}"

rule convert_to_fpileup:
    input:
        "results/A04_mapped_contigs/{sample}/sorted_bam/Contig{nr}_AT_sort.bam"
    output:
        temp("results/A04_mapped_contigs/{sample}/pileup/Contig{nr}_AT_sort.pileup")
    shell:
        "samtools mpileup -B {input} > {output}"

rule SNP_calling:
    input:
        "results/A04_mapped_contigs/{sample}/pileup/Contig{nr}_AT_sort.pileup"
    output:
        "results/A04_mapped_contigs/{sample}/var/Contig{nr}_AT_sort.var"
    shell:
        "varscan pileup2cns {input} "
        "--min-freq-for-hom 0.6 "
        "--min-coverage 5 "
        "--min-var-freq 0.6 "
        "--p-value 0.1 "
        "--min-reads2 5 "
        "> {output}"

rule make_contig_consensus:
    input:
        script = "src/read_var.py",
        file = "results/A04_mapped_contigs/{sample}/var/Contig{nr}_AT_sort.var"
    output:
        "results/A05_consensus_contigs/{sample}/Contig{nr}.fasta"
    shell:
        "python3 {input.script} {input.file}"

rule BLAT_assembled:
    input:
        "data/exons/exons_AT.fasta",
        "results/A05_consensus_contigs/{sample}/Contig{nr}.fasta"
    output:
        "results/A06_identified_contigs_blat/{sample}/contig{nr}_AT.psl"
    shell:
        "blat "
        "-t=dnax "
        "-q=dnax "
        "-stepSize=5 "
        "-repMatch=2253 "
        "-minScore=0 "
        "-minIdentity=0 "
        "{input} {output}"

## part 4:
rule calculate_avcov:
    input:
        script = "src/calculate_average_coverage.py"
    output:
        "results/A04_mapped_contigs/{sample}/var/{sample}_average_coverage.txt"
    params:
        sample = "{sample}"
    shell:
        "python {input.script} {params.sample}"

rule extract_hits_psl:
    input:
        script = "src/extract_hits_psl.py"
        # file = "results/A06_identified_contigs_blat/{sample}/contig{nr}_AT.psl"
    output:
        "results/A07_mapped_exons/{sample}/stats/sequenced_exons.txt"
    params:
        sample = "{sample}"
    shell:
        "python {input.script} {params.sample}"

rule calculate_mapped_reads:
    input:
         file = "results/A03_mapped_reads/{sample}/YASRA_related_files/alignments_{sample}_reads.fq_ref-at.fasta.sam"
    output:
         file = "results/A03_mapped_reads/{sample}/mapped_reads.txt"
    shell:
        "cat {input.file} | grep '>' | wc -l > {output.file}"

rule calculate_contigs_formed:
    input:
         file = "results/A03_mapped_reads/{sample}/YASRA_related_files/Final_Assembly_{sample}_reads.fq_ref-at.fasta"
    output:
         file = "results/A03_mapped_reads/{sample}/contigs_formed.txt"
    shell:
         "cat {input.file} | grep '>' | wc -l > {output.file}"


## part 5:
rule MAFFT_assembly:
    input:
        "results/A07_mapped_exons/{sample}/{exon}.fasta"
    output:
        "results/A08_aligned_exons/{sample}/{exon}.fasta"
    shell:
        "mafft "
        "--maxiterate 1000 "
        "--oldgenafpair "
        "{input} > {output}"

rule make_exon_consensus:
    input:
        script = "src/make_exon_consensus.py",
        file = "results/A08_aligned_exons/{sample}/{exon}.fasta"
    output:
        "results/A09_consensus_exons/{sample}/{exon}.fasta"
    params:
         "{sample}"
    shell:
        "python {input.script} {params}"

rule calc_identified_contigs:
    input:
         file = "results/A06_identified_contigs_blat/{sample}/stats/highest_hits_filtered.txt"
    output:
         file = "results/A06_identified_contigs_blat/{sample}/stats/identified_contigs.txt"
    shell:
        "echo $(cat {input.file} | wc -l) - 1 | bc > {output.file}"


# part 6:
rule calculate_called_exons:
    input:
        dir = "results/A09_consensus_exons/{sample}/"
    output:
        file = "results/A09_consensus_exons/{sample}/called_exons.txt"
    shell:
        "echo $(ls {input.dir} | wc -l) - 1 | bc > {output.file}"

# part 7
rule merge_exon_seqs:
    input:
        script = "src/merge_exon_seqs.py",
        file = "results/A09_consensus_exons/"
    output:
        "results/A10_all_samples_exons/"
    shell:
         "python {input.script}"
